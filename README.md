# ML_Fundamentals_Applications

## Огляд

Цей проєкт демонструє побудову конвеєра машинного навчання для задачі класифікації із застосуванням таких методів:

- Попередня обробка даних
- Балансування класів
- Побудова моделі
- Оптимізація гіперпараметрів
- Крос-валідація

---

## Використані бібліотеки та їх застосування

- **Pandas**: завантаження та обробка даних.
- **NumPy**: робота з числовими даними та обчислення.
- **Scikit-learn**:
  - `IsolationForest`: видалення аномалій.
  - `StandardScaler`: масштабування числових ознак.
  - `SimpleImputer`: імпутація відсутніх значень.
  - `Pipeline`: побудова конвеєра.
  - `RandomForestClassifier`: класифікатор для задачі.
  - `StratifiedKFold`, `cross_val_score`: крос-валідація.
  - `classification_report`, `balanced_accuracy_score`: оцінка якості моделі.
  - `ColumnTransformer`: трансформація ознак.
- **imbalanced-learn**:
  - `SMOTE`: балансування класів через оверсемплінг.
- **optuna**: пошук оптимальних гіперпараметрів моделі.
- **category-encoders**:
  - `CountEncoder`: частотне кодування категоріальних змінних.

---

## Кроки побудови моделі

### 1. Встановлення залежностей

```bash
pip install pandas numpy scikit-learn imbalanced-learn optuna category_encoders
```

### 2. Попередня обробка даних

- **Видалення дублікатів.**
- **Створення колонок з кількістю пропусків:**
  - `cat_missing_count`: кількість пропусків у категоріальних колонках.
  - `float_missing_count`: кількість пропусків у числових (float) колонках.
  - `int_missing_count`: кількість пропусків у числових (int) колонках.
- **Видалення колонок із високим рівнем пропусків** (≥50%).
- **Видалення категоріальних колонок з високою кардинальністю** (кількість унікальних значень > 50).
- **Частотне кодування категоріальних змінних** за допомогою `CountEncoder`.
- **Імпутація відсутніх значень:**
  - Для числових колонок:
    - Якщо пропусків < 30% – використовується **медіана**.
    - Якщо пропусків ≥ 30% – використовується **середнє значення**.
  - Для категоріальних колонок:
    - Якщо пропусків < 30% – заповнюється **найбільш частим значенням**.
    - Якщо пропусків ≥ 30% – заповнюється значенням `"Unknown"`.
- **Видалення аномалій** за допомогою `IsolationForest`.
- **Інженіринг ознак:**
  - Додавання колонок із довжинами рядків для категоріальних змінних.
  - Додавання агрегованих числових ознак: `sum_row`, `mean_row`, `std_row` тощо.

---   

### 3. Підготовка до моделювання

- **Розділення даних на:**
  - Цільову змінну (`y`).
  - Ознаки (`X`).
- **Масштабування числових ознак** за допомогою `StandardScaler`.

---

### 4. Побудова моделі

- **Побудова конвеєра:**
  - Балансування класів за допомогою `SMOTE`.
  - Використання `RandomForestClassifier` як основного класифікатора.
- **Оцінка базової моделі** через крос-валідацію за допомогою `StratifiedKFold`.

---

### 5. Оптимізація гіперпараметрів

- Використання **Optuna** для підбору оптимальних параметрів `RandomForestClassifier`:
  - `n_estimators`, `max_depth`, `min_samples_split`, `min_samples_leaf`.
- **Збереження найкращих параметрів** у файл `best_params.txt`.

---

### 6. Фінальна модель

- **Побудова моделі** з оптимальними параметрами.
- **Оцінка якості** на валідаційному наборі (hold-out set).

---

### 7. Прогнозування

- **Прогнозування на тестовому наборі.**
- **Збереження результатів** у файл `submission_rf.csv`.

---

## Результати

- **CV Balanced Accuracy**: Оцінено базову модель через крос-валідацію.
- **Оптимізована модель:**
  - Найкращі параметри знайдені через `Optuna`.
- **Фінальна модель:**
  - Balanced Accuracy на валідаційному наборі (hold-out set): ~`0.8766`.

---

## Файли

- `final_proj_data.csv`: навчальні дані.
- `final_proj_test.csv`: тестові дані.
- `submission_rf.csv`: результати прогнозів.
- `best_params.txt`: найкращі гіперпараметри моделі.

